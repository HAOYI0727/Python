# """
# è¿è¡Œæ•°æ®é¢„å¤„ç†æµç¨‹ï¼Œç”Ÿæˆç‰¹å¾å·¥ç¨‹æ‰€éœ€æ–‡ä»¶
# """

# import pandas as pd
# import numpy as np
# from pathlib import Path
# import sys

# # æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
# project_path = Path("D:/VSCodeProjects/PythonCourse")
# src_path = project_path / "src"
# sys.path.append(str(src_path))

# def complete_preprocessing():
#     """å®Œæˆæ•°æ®é¢„å¤„ç†æµç¨‹"""
#     print("ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†æµç¨‹...")
    
#     # åŠ è½½åŸå§‹æ•°æ®
#     raw_path = project_path / "data" / "raw"
#     movies = pd.read_csv(raw_path / "movies.csv")
#     ratings = pd.read_csv(raw_path / "ratings.csv")
#     links = pd.read_csv(raw_path / "links.csv")
#     tags = pd.read_csv(raw_path / "tags.csv")
    
#     print("âœ… åŸå§‹æ•°æ®åŠ è½½å®Œæˆ")
#     print(f"   Movies: {movies.shape}")
#     print(f"   Ratings: {ratings.shape}")
#     print(f"   Links: {links.shape}")
#     print(f"   Tags: {tags.shape}")
    
#     # æ•°æ®é¢„å¤„ç†æ­¥éª¤
#     processed_data = preprocess_data(movies, ratings, links, tags)
    
#     # ä¿å­˜å¤„ç†åçš„æ•°æ®
#     save_processed_data(processed_data)
    
#     print("ğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")

# def preprocess_data(movies, ratings, links, tags):
#     """æ•°æ®é¢„å¤„ç†"""
#     print("\nğŸ”§ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
    
#     # 1. å¤„ç†ç”µå½±æ•°æ®
#     movies_processed = process_movies(movies)
    
#     # 2. å¤„ç†è¯„åˆ†æ•°æ®
#     ratings_processed = process_ratings(ratings)
    
#     # 3. åˆ›å»ºç”µå½±ç‰¹å¾æ•°æ®é›†
#     movie_features = create_movie_features(movies_processed, ratings_processed, links)
    
#     # 4. å¤„ç†ç¼ºå¤±å€¼
#     movie_features_clean = handle_missing_values(movie_features)
    
#     return {
#         'movies_processed': movies_processed,
#         'ratings_processed': ratings_processed,
#         'movie_features': movie_features,
#         'movie_features_clean': movie_features_clean
#     }

# def process_movies(movies):
#     """å¤„ç†ç”µå½±æ•°æ®"""
#     print("   ğŸ¬ å¤„ç†ç”µå½±æ•°æ®...")
    
#     # åˆ›å»ºå‰¯æœ¬
#     movies_proc = movies.copy()
    
#     # ä»æ ‡é¢˜ä¸­æå–å¹´ä»½
#     movies_proc['year'] = movies_proc['title'].str.extract(r'\((\d{4})\)')
#     movies_proc['year'] = pd.to_numeric(movies_proc['year'], errors='coerce')
    
#     # å¡«å……å¹´ä»½ç¼ºå¤±å€¼
#     year_median = movies_proc['year'].median()
#     movies_proc['year'].fillna(year_median, inplace=True)
    
#     # å¤„ç†ç”µå½±ç±»å‹
#     movies_proc['genres_list'] = movies_proc['genres'].str.split('|')
    
#     # åˆ›å»ºç±»å‹è™šæ‹Ÿå˜é‡
#     all_genres = set()
#     for genres in movies_proc['genres_list'].dropna():
#         all_genres.update(genres)
    
#     for genre in all_genres:
#         movies_proc[f'genre_{genre}'] = movies_proc['genres_list'].apply(
#             lambda x: 1 if genre in x else 0
#         )
    
#     print(f"      åˆ›å»ºäº† {len(all_genres)} ç§ç”µå½±ç±»å‹ç¼–ç ")
#     return movies_proc

# def process_ratings(ratings):
#     """å¤„ç†è¯„åˆ†æ•°æ®"""
#     print("   â­ å¤„ç†è¯„åˆ†æ•°æ®...")
    
#     # ç§»é™¤é‡å¤è¯„åˆ†ï¼ˆåŒä¸€ç”¨æˆ·å¯¹åŒä¸€ç”µå½±çš„å¤šæ¬¡è¯„åˆ†ï¼‰
#     initial_count = len(ratings)
#     ratings_proc = ratings.drop_duplicates(subset=['userId', 'movieId'], keep='last')
#     removed_count = initial_count - len(ratings_proc)
    
#     print(f"      ç§»é™¤äº† {removed_count} æ¡é‡å¤è¯„åˆ†")
#     return ratings_proc

# def create_movie_features(movies, ratings, links):
#     """åˆ›å»ºç”µå½±ç‰¹å¾æ•°æ®é›†"""
#     print("   ğŸ—ï¸ åˆ›å»ºç”µå½±ç‰¹å¾æ•°æ®é›†...")
    
#     # è®¡ç®—æ¯ä¸ªç”µå½±çš„è¯„åˆ†ç»Ÿè®¡
#     movie_stats = ratings.groupby('movieId').agg({
#         'rating': ['mean', 'count', 'std', 'min', 'max'],
#         'userId': 'nunique',
#         'timestamp': ['min', 'max']
#     }).round(3)
    
#     # æ‰å¹³åŒ–åˆ—å
#     movie_stats.columns = [
#         'avg_rating', 'rating_count', 'rating_std', 
#         'min_rating', 'max_rating', 'unique_users',
#         'first_rating_date', 'last_rating_date'
#     ]
    
#     # è®¡ç®—è¯„åˆ†æ—¶é—´è·¨åº¦ï¼ˆå¤©ï¼‰
#     movie_stats['rating_period_days'] = (
#         movie_stats['last_rating_date'] - movie_stats['first_rating_date']
#     ) / (24 * 3600)
    
#     # åˆå¹¶ç”µå½±åŸºæœ¬ä¿¡æ¯å’Œè¯„åˆ†ç»Ÿè®¡
#     movie_features = movies.merge(
#         movie_stats, 
#         left_on='movieId', 
#         right_index=True, 
#         how='left'
#     )
    
#     # åˆå¹¶é“¾æ¥ä¿¡æ¯
#     movie_features = movie_features.merge(
#         links, 
#         on='movieId', 
#         how='left'
#     )
    
#     print(f"      åˆ›å»ºçš„ç‰¹å¾æ•°æ®é›†: {movie_features.shape}")
#     return movie_features

# def handle_missing_values(movie_features):
#     """å¤„ç†ç¼ºå¤±å€¼"""
#     print("   ğŸ§¹ å¤„ç†ç¼ºå¤±å€¼...")
    
#     # åˆ›å»ºå‰¯æœ¬
#     movie_features_clean = movie_features.copy()
    
#     # å®šä¹‰å¡«å……ç­–ç•¥
#     fill_strategy = {
#         # è¯„åˆ†ç›¸å…³åˆ—ï¼šç¼ºå¤±è¡¨ç¤ºæ— è¯„åˆ†ï¼Œå¡«å……0
#         'avg_rating': 0,
#         'min_rating': 0, 
#         'max_rating': 0,
#         'rating_std': 0,
#         'unique_users': 0,
#         'rating_count': 0,
#         'first_rating_date': 0,
#         'last_rating_date': 0, 
#         'rating_period_days': 0,
#         # å¤–éƒ¨IDï¼šå¡«å……0
#         'imdbId': 0,
#         'tmdbId': 0,
#         # å¹´ä»½ï¼šå¡«å……ä¸­ä½æ•°
#         'year': movie_features['year'].median()
#     }
    
#     # åº”ç”¨å¡«å……ç­–ç•¥
#     for col, value in fill_strategy.items():
#         if col in movie_features_clean.columns:
#             before = movie_features_clean[col].isnull().sum()
#             movie_features_clean[col] = movie_features_clean[col].fillna(value)
#             after = movie_features_clean[col].isnull().sum()
#             if before > 0:
#                 print(f"      å¡«å…… {col}: {before} â†’ {after} ä¸ªç¼ºå¤±å€¼")
    
#     # æ£€æŸ¥å‰©ä½™ç¼ºå¤±å€¼
#     remaining_missing = movie_features_clean.isnull().sum().sum()
#     print(f"      å‰©ä½™ç¼ºå¤±å€¼æ€»æ•°: {remaining_missing}")
    
#     return movie_features_clean

# def save_processed_data(processed_data):
#     """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
#     print("\nğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
    
#     processed_path = project_path / "data" / "processed"
#     processed_path.mkdir(parents=True, exist_ok=True)
    
#     # ä¿å­˜å„ä¸ªæ•°æ®æ–‡ä»¶
#     processed_data['movies_processed'].to_csv(processed_path / "movies_processed.csv", index=False)
#     processed_data['ratings_processed'].to_csv(processed_path / "ratings_processed.csv", index=False)
#     processed_data['movie_features'].to_csv(processed_path / "movie_features.csv", index=False)
#     processed_data['movie_features_clean'].to_csv(processed_path / "movie_features_clean.csv", index=False)
    
#     print("âœ… æ•°æ®ä¿å­˜å®Œæˆ:")
#     print(f"   - movies_processed.csv")
#     print(f"   - ratings_processed.csv") 
#     print(f"   - movie_features.csv")
#     print(f"   - movie_features_clean.csv")
    
#     # æ•°æ®è´¨é‡æŠ¥å‘Š
#     movie_features_clean = processed_data['movie_features_clean']
#     print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®è´¨é‡:")
#     print(f"   æ•°æ®é›†å½¢çŠ¶: {movie_features_clean.shape}")
#     print(f"   æ€»ç¼ºå¤±å€¼: {movie_features_clean.isnull().sum().sum()}")
#     print(f"   ç”µå½±æ•°é‡: {len(movie_features_clean)}")
#     print(f"   ç‰¹å¾æ•°é‡: {len(movie_features_clean.columns)}")

# if __name__ == "__main__":
#     complete_preprocessing()