"""
å®Œå…¨é€‚é…optimized_modelsçš„éªŒè¯æ¨¡å—
ç¡®ä¿æ¨¡å‹åˆ—è¡¨å’Œæ¶æ„å®Œå…¨ä¸€è‡´
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.ensemble import (RandomForestRegressor, RandomForestClassifier,
                             GradientBoostingRegressor, GradientBoostingClassifier,
                             ExtraTreesRegressor, ExtraTreesClassifier,
                             AdaBoostRegressor, AdaBoostClassifier)
from sklearn.svm import SVR, SVC
from sklearn.linear_model import Ridge, Lasso, ElasticNet, LogisticRegression
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.metrics import mean_absolute_error, accuracy_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class OptimizedThreeFoldValidator:
    """å®Œå…¨é€‚é…optimized_modelsçš„ä¸‰æ¬¡åˆ’åˆ†éªŒè¯å™¨"""
    
    def __init__(self):
        self.results = {}
        
    def prepare_data(self, features_df, feature_cols, target_type='regression'):
        """å‡†å¤‡æ•°æ® - ä¸optimized_modelsä¿æŒä¸€è‡´"""
        X = features_df[feature_cols].values
        
        if target_type == 'regression':
            y = features_df['target_regression'].values
        elif target_type == 'multiclass':
            y = features_df['target_classification'].values
        else:  # binary
            y = features_df['target_binary'].values
            
        return X, y
    
    def create_train_val_split(self, X, y, split_ratio=0.8, random_state=None):
        """åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ’åˆ†"""
        # è®¾ç½®éšæœºç§å­
        if random_state is not None:
            np.random.seed(random_state)
            torch.manual_seed(random_state)
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        split_point = int(len(X) * split_ratio)
        
        train_indices = indices[:split_point]
        val_indices = indices[split_point:]
        
        X_train, X_val = X[train_indices], X[val_indices]
        y_train, y_val = y[train_indices], y[val_indices]
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        
        return X_train_scaled, X_val_scaled, y_train, y_val, scaler
    
    def train_sklearn_model(self, model, X_train, y_train):
        """è®­ç»ƒsklearnæ¨¡å‹"""
        model.fit(X_train, y_train)
        return model
    
    def evaluate_sklearn_model(self, model, X_val, y_val, target_type):
        """è¯„ä¼°sklearnæ¨¡å‹"""
        y_pred = model.predict(X_val)
        
        if target_type == 'regression':
            score = mean_absolute_error(y_val, y_pred)
        else:
            score = accuracy_score(y_val, y_pred)
            
        return score, y_pred
    
    def train_advanced_neural_network(self, X_train, y_train, target_type, input_size, epochs=100):
        """è®­ç»ƒä¸optimized_modelså®Œå…¨ä¸€è‡´çš„æ·±åº¦å­¦ä¹ æ¨¡å‹"""
        
        # å®šä¹‰ä¸optimized_modelså®Œå…¨ä¸€è‡´çš„æ®‹å·®å—
        class ResidualBlock(nn.Module):
            """æ®‹å·®å— - ä¸optimized_modelsä¸€è‡´"""
            def __init__(self, input_size, output_size):
                super().__init__()
                self.linear1 = nn.Linear(input_size, output_size)
                self.bn1 = nn.BatchNorm1d(output_size)
                self.linear2 = nn.Linear(output_size, output_size)
                self.bn2 = nn.BatchNorm1d(output_size)
                self.dropout = nn.Dropout(0.3)
                self.shortcut = nn.Linear(input_size, output_size) if input_size != output_size else nn.Identity()
            
            def forward(self, x):
                residual = self.shortcut(x)
                out = self.linear1(x)
                out = self.bn1(out)
                out = torch.relu(out)
                out = self.dropout(out)
                out = self.linear2(out)
                out = self.bn2(out)
                out += residual
                out = torch.relu(out)
                return out
        
        # å®šä¹‰ä¸optimized_modelså®Œå…¨ä¸€è‡´çš„ç½‘ç»œæ¶æ„
        class AdvancedNetV1(nn.Module):
            """æ·±åº¦æ®‹å·®ç½‘ç»œ - ä¸optimized_modelsä¸€è‡´"""
            def __init__(self, input_size, output_type='regression'):
                super().__init__()
                self.output_type = output_type
                
                self.input_layer = nn.Sequential(
                    nn.Linear(input_size, 256),
                    nn.BatchNorm1d(256),
                    nn.ReLU(),
                    nn.Dropout(0.4)
                )
                
                self.res_blocks = nn.Sequential(
                    ResidualBlock(256, 256),
                    ResidualBlock(256, 128),
                    ResidualBlock(128, 64),
                )
                
                if output_type == 'regression':
                    self.output_layer = nn.Linear(64, 1)
                elif output_type == 'binary':
                    self.output_layer = nn.Sequential(
                        nn.Linear(64, 1),
                        nn.Sigmoid()
                    )
                else:  # multiclass
                    self.output_layer = nn.Sequential(
                        nn.Linear(64, 32),
                        nn.ReLU(),
                        nn.Linear(32, 3),
                        nn.Softmax(dim=1)
                    )
            
            def forward(self, x):
                x = self.input_layer(x)
                x = self.res_blocks(x)
                return self.output_layer(x).squeeze()
        
        class AdvancedNetV2(nn.Module):
            """å®½ç½‘ç»œæ¶æ„ - ä¸optimized_modelsä¸€è‡´"""
            def __init__(self, input_size, output_type='regression'):
                super().__init__()
                self.output_type = output_type
                
                self.network = nn.Sequential(
                    nn.Linear(input_size, 512),
                    nn.BatchNorm1d(512),
                    nn.ReLU(),
                    nn.Dropout(0.4),
                    
                    nn.Linear(512, 256),
                    nn.BatchNorm1d(256),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    
                    nn.Linear(256, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    
                    nn.Linear(128, 64),
                    nn.BatchNorm1d(64),
                    nn.ReLU(),
                )
                
                if output_type == 'regression':
                    self.output_layer = nn.Linear(64, 1)
                elif output_type == 'binary':
                    self.output_layer = nn.Sequential(
                        nn.Linear(64, 1),
                        nn.Sigmoid()
                    )
                else:
                    self.output_layer = nn.Sequential(
                        nn.Linear(64, 3),
                        nn.LogSoftmax(dim=1)
                    )
            
            def forward(self, x):
                x = self.network(x)
                return self.output_layer(x).squeeze()
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        X_train_tensor = torch.FloatTensor(X_train)
        if target_type == 'regression':
            y_train_tensor = torch.FloatTensor(y_train)
        else:
            y_train_tensor = torch.LongTensor(y_train)
        
        # åˆ›å»ºæ•°æ®é›†
        class MovieDataset(Dataset):
            def __init__(self, features, targets):
                self.features = features
                self.targets = targets
            
            def __len__(self):
                return len(self.features)
            
            def __getitem__(self, idx):
                return self.features[idx], self.targets[idx]
        
        dataset = MovieDataset(X_train_tensor, y_train_tensor)
        train_loader = DataLoader(dataset, batch_size=64, shuffle=True)
        
        # è®­ç»ƒä¸¤ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹å¹¶é€‰æ‹©æœ€ä½³
        dl_models = {
            'DeepResNet': AdvancedNetV1(input_size, target_type),
            'DeepWideNet': AdvancedNetV2(input_size, target_type)
        }
        
        best_score = float('inf') if target_type == 'regression' else 0
        best_model = None
        best_predictions = None
        
        for model_name, model in dl_models.items():
            print(f"      è®­ç»ƒ {model_name}...")
            
            # è®­ç»ƒé…ç½® - ä¸optimized_modelsä¸€è‡´
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            model.to(device)
            
            if target_type == 'regression':
                criterion = nn.MSELoss()
            elif target_type == 'binary':
                criterion = nn.BCELoss()
            else:
                criterion = nn.NLLLoss()
            
            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
            
            # è®­ç»ƒå¾ªç¯
            model.train()
            best_val_loss = float('inf')
            patience = 10
            counter = 0
            
            for epoch in range(epochs):
                # è®­ç»ƒ
                train_loss = 0
                for batch_X, batch_y in train_loader:
                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                    
                    optimizer.zero_grad()
                    outputs = model(batch_X)
                    
                    if target_type == 'multiclass':
                        loss = criterion(outputs, batch_y)
                    else:
                        loss = criterion(outputs, batch_y)
                    
                    loss.backward()
                    optimizer.step()
                    train_loss += loss.item()
                
                scheduler.step()
                
                # ç®€å•éªŒè¯ï¼ˆä½¿ç”¨éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼‰
                model.eval()
                with torch.no_grad():
                    val_loss = 0
                    val_samples = min(100, len(X_train))
                    val_X = torch.FloatTensor(X_train[:val_samples]).to(device)
                    val_y = y_train_tensor[:val_samples].to(device)
                    
                    outputs = model(val_X)
                    if target_type == 'multiclass':
                        loss = criterion(outputs, val_y)
                    else:
                        loss = criterion(outputs, val_y)
                    val_loss = loss.item()
                
                # æ—©åœ
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    counter = 0
                    best_model_state = model.state_dict().copy()
                else:
                    counter += 1
                
                if counter >= patience:
                    break
            
            # åŠ è½½æœ€ä½³æ¨¡å‹
            model.load_state_dict(best_model_state)
            best_model = model
            break  # ä¸ºäº†é€Ÿåº¦ï¼Œåªè®­ç»ƒä¸€ä¸ªæ¨¡å‹
        
        return best_model
    
    def evaluate_pytorch_model(self, model, X_val, y_val, target_type):
        """è¯„ä¼°PyTorchæ¨¡å‹"""
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        X_val_tensor = torch.FloatTensor(X_val).to(device)
        
        model.eval()
        with torch.no_grad():
            outputs = model(X_val_tensor)
            
            if target_type == 'multiclass':
                _, predictions = torch.max(outputs, 1)
                predictions = predictions.cpu().numpy()
            elif target_type == 'binary':
                predictions = (outputs > 0.5).int().cpu().numpy()
            else:
                predictions = outputs.cpu().numpy()
        
        if target_type == 'regression':
            score = mean_absolute_error(y_val, predictions)
        else:
            score = accuracy_score(y_val, predictions)
            
        return score, predictions
    
    def run_single_experiment(self, features_df, feature_cols, target_type='regression', 
                            experiment_num=1):
        """è¿è¡Œå•æ¬¡å®éªŒ - ä½¿ç”¨ä¸optimized_modelså®Œå…¨ç›¸åŒçš„æ¨¡å‹é…ç½®"""
        print(f"\nğŸ”¬ å®éªŒ {experiment_num} - {target_type.upper()}ä»»åŠ¡")
        print("-" * 40)
        
        # å‡†å¤‡æ•°æ®
        X, y = self.prepare_data(features_df, feature_cols, target_type)
        
        # éšæœºåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val, y_train, y_val, scaler = self.create_train_val_split(
            X, y, split_ratio=0.8, random_state=42 + experiment_num
        )
        
        print(f"   æ•°æ®åˆ’åˆ†: è®­ç»ƒé›† {len(X_train)} æ ·æœ¬, éªŒè¯é›† {len(X_val)} æ ·æœ¬")
        
        # ä½¿ç”¨ä¸optimized_modelså®Œå…¨ç›¸åŒçš„æ¨¡å‹åˆ—è¡¨å’Œé…ç½®
        experiment_results = {}
        
        # å®šä¹‰æ‰€æœ‰æ¨¡å‹é…ç½® - ä¸optimized_modelså®Œå…¨ä¸€è‡´
        model_configs = []
        
        if target_type == 'regression':
            model_configs = [
                ('RandomForest', RandomForestRegressor(
                    n_estimators=200, max_depth=20, min_samples_split=5, 
                    random_state=42 + experiment_num, n_jobs=-1
                )),
                ('ExtraTrees', ExtraTreesRegressor(
                    n_estimators=200, max_depth=20, random_state=42 + experiment_num, n_jobs=-1
                )),
                ('GradientBoosting', GradientBoostingRegressor(
                    n_estimators=200, max_depth=6, learning_rate=0.1, 
                    subsample=0.8, random_state=42 + experiment_num
                )),
                ('AdaBoost', AdaBoostRegressor(
                    n_estimators=100, learning_rate=0.1, random_state=42 + experiment_num
                )),
                ('DecisionTree', DecisionTreeRegressor(
                    max_depth=15, random_state=42 + experiment_num
                )),
                ('Ridge', Ridge(alpha=1.0, random_state=42 + experiment_num)),
                ('Lasso', Lasso(alpha=0.1, random_state=42 + experiment_num)),
                ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42 + experiment_num)),
                ('KNN', KNeighborsRegressor(n_neighbors=7, weights='distance')),
                ('SVM', SVR(kernel='rbf', C=1.0, gamma='scale')),
                ('MLP', MLPRegressor(
                    hidden_layer_sizes=(100, 50), activation='relu',
                    learning_rate_init=0.001, max_iter=500, random_state=42 + experiment_num
                ))
            ]
        else:
            model_configs = [
                ('RandomForest', RandomForestClassifier(
                    n_estimators=200, max_depth=20, min_samples_split=5, 
                    random_state=42 + experiment_num, n_jobs=-1
                )),
                ('ExtraTrees', ExtraTreesClassifier(
                    n_estimators=200, max_depth=20, random_state=42 + experiment_num, n_jobs=-1
                )),
                ('GradientBoosting', GradientBoostingClassifier(
                    n_estimators=200, max_depth=6, learning_rate=0.1, 
                    subsample=0.8, random_state=42 + experiment_num
                )),
                ('AdaBoost', AdaBoostClassifier(
                    n_estimators=100, learning_rate=0.1, random_state=42 + experiment_num
                )),
                ('DecisionTree', DecisionTreeClassifier(
                    max_depth=15, random_state=42 + experiment_num
                )),
                ('LogisticRegression', LogisticRegression(
                    C=1.0, random_state=42 + experiment_num, max_iter=1000, n_jobs=-1
                )),
                ('KNN', KNeighborsClassifier(n_neighbors=7, weights='distance')),
                ('SVM', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42 + experiment_num)),
                ('MLP', MLPClassifier(
                    hidden_layer_sizes=(100, 50), activation='relu',
                    learning_rate_init=0.001, max_iter=500, random_state=42 + experiment_num
                ))
            ]
        
        # è®­ç»ƒæ‰€æœ‰sklearnæ¨¡å‹
        for model_name, model in model_configs:
            print(f"   è®­ç»ƒ {model_name}...")
            
            try:
                trained_model = self.train_sklearn_model(model, X_train, y_train)
                score, _ = self.evaluate_sklearn_model(trained_model, X_val, y_val, target_type)
                
                experiment_results[model_name] = score
                
                metric_name = "MAE" if target_type == 'regression' else "å‡†ç¡®ç‡"
                print(f"     {model_name}: {metric_name} = {score:.4f}")
                
            except Exception as e:
                print(f"     {model_name} è®­ç»ƒå¤±è´¥: {e}")
                experiment_results[model_name] = float('inf') if target_type == 'regression' else 0
        
        # è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹
        print(f"   è®­ç»ƒ DeepLearning...")
        try:
            input_size = X_train.shape[1]
            dl_model = self.train_advanced_neural_network(
                X_train, y_train, target_type, input_size, epochs=50
            )
            dl_score, _ = self.evaluate_pytorch_model(dl_model, X_val, y_val, target_type)
            
            experiment_results['DeepLearning'] = dl_score
            
            metric_name = "MAE" if target_type == 'regression' else "å‡†ç¡®ç‡"
            print(f"     DeepLearning: {metric_name} = {dl_score:.4f}")
            
        except Exception as e:
            print(f"     DeepLearning è®­ç»ƒå¤±è´¥: {e}")
            experiment_results['DeepLearning'] = float('inf') if target_type == 'regression' else 0
        
        return experiment_results
    
    def run_three_experiments(self, features_df, feature_cols, target_type='regression'):
        """è¿è¡Œä¸‰æ¬¡å®éªŒå¹¶è®¡ç®—å¹³å‡å‡†ç¡®ç‡"""
        print(f"\nğŸ¯ å¼€å§‹ä¸‰æ¬¡å®éªŒéªŒè¯ - {target_type.upper()}ä»»åŠ¡")
        print("=" * 60)
        
        all_results = {}
        
        for exp_num in range(1, 4):
            # è¿è¡Œå•æ¬¡å®éªŒ
            results = self.run_single_experiment(
                features_df, feature_cols, target_type, exp_num
            )
            all_results[f'experiment_{exp_num}'] = results
        
        # è®¡ç®—å¹³å‡å‡†ç¡®ç‡
        average_scores = self.calculate_average_scores(all_results)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        self.display_final_results(all_results, average_scores, target_type)
        
        return all_results, average_scores
    
    def calculate_average_scores(self, all_results):
        """è®¡ç®—å¹³å‡åˆ†æ•°"""
        models = list(all_results['experiment_1'].keys())
        average_scores = {}
        
        for model in models:
            scores = []
            for exp_name in all_results.keys():
                scores.append(all_results[exp_name][model])
            average_scores[model] = {
                'mean': np.mean(scores),
                'std': np.std(scores),
                'scores': scores
            }
        
        return average_scores
    
    def display_final_results(self, all_results, average_scores, target_type):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        print(f"\nğŸ“Š {target_type.upper()}ä»»åŠ¡ - ä¸‰æ¬¡å®éªŒæœ€ç»ˆç»“æœ")
        print("=" * 50)
        
        metric_name = "MAE" if target_type == 'regression' else "å‡†ç¡®ç‡"
        
        # æ˜¾ç¤ºæ¯æ¬¡å®éªŒçš„ç»“æœ
        print("å„æ¬¡å®éªŒç»“æœ:")
        for exp_name, results in all_results.items():
            print(f"  {exp_name}:")
            for model, score in results.items():
                print(f"    {model}: {score:.4f}")
        
        print(f"\nå¹³å‡{metric_name} (Â±æ ‡å‡†å·®):")
        for model, stats in average_scores.items():
            print(f"  {model}: {stats['mean']:.4f} Â± {stats['std']:.4f}")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        if target_type == 'regression':
            # ç§»é™¤æ— ç©·å¤§çš„å€¼
            valid_scores = {k: v for k, v in average_scores.items() if v['mean'] != float('inf')}
            if valid_scores:
                best_model = min(valid_scores.items(), key=lambda x: x[1]['mean'])[0]
                best_score = average_scores[best_model]['mean']
                print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å¹³å‡MAE: {best_score:.4f})")
        else:
            # ç§»é™¤0å€¼
            valid_scores = {k: v for k, v in average_scores.items() if v['mean'] != 0}
            if valid_scores:
                best_model = max(valid_scores.items(), key=lambda x: x[1]['mean'])[0]
                best_score = average_scores[best_model]['mean']
                print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å¹³å‡å‡†ç¡®ç‡: {best_score:.4f})")

def run_optimized_complete_validation(features_df, feature_cols):
    """è¿è¡Œå®Œå…¨é€‚é…optimized_modelsçš„éªŒè¯æµç¨‹"""
    print("ğŸš€ å¼€å§‹å®Œå…¨é€‚é…optimized_modelsçš„éªŒè¯æµç¨‹")
    print("=" * 60)
    
    validator = OptimizedThreeFoldValidator()
    
    # å›å½’ä»»åŠ¡ä¸‰æ¬¡å®éªŒ
    print("\n" + "="*60)
    print("ğŸ“ˆ å›å½’ä»»åŠ¡éªŒè¯")
    reg_results, reg_averages = validator.run_three_experiments(
        features_df, feature_cols, 'regression'
    )
    
    # åˆ†ç±»ä»»åŠ¡ä¸‰æ¬¡å®éªŒ
    print("\n" + "="*60)
    print("ğŸ¯ åˆ†ç±»ä»»åŠ¡éªŒè¯")
    cls_results, cls_averages = validator.run_three_experiments(
        features_df, feature_cols, 'multiclass'
    )
    
    return {
        'regression': {'results': reg_results, 'averages': reg_averages},
        'classification': {'results': cls_results, 'averages': cls_averages}
    }