"""
æ¨¡å‹è®­ç»ƒä¸éªŒè¯æ¨¡å—
ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¿›è¡Œä¸‰æ¬¡éšæœºåˆ’åˆ†ã€è®­ç»ƒå’ŒéªŒè¯
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier
from sklearn.svm import SVR, SVC
from sklearn.linear_model import Ridge, Lasso, LogisticRegression
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.metrics import mean_absolute_error, accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class ThreeFoldValidator:
    """ä¸‰æ¬¡åˆ’åˆ†éªŒè¯å™¨"""
    
    def __init__(self):
        self.results = {}
        
    def prepare_data(self, features_df, feature_cols, target_type='regression'):
        """å‡†å¤‡æ•°æ®"""
        X = features_df[feature_cols].values
        
        if target_type == 'regression':
            y = features_df['target_regression'].values
        elif target_type == 'multiclass':
            y = features_df['target_classification'].values
        else:  # binary
            y = features_df['target_binary'].values
            
        return X, y
    
    def create_train_val_split(self, X, y, split_ratio=0.8, random_state=None):
        """åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ’åˆ†"""
        # è®¾ç½®éšæœºç§å­
        if random_state is not None:
            np.random.seed(random_state)
            torch.manual_seed(random_state)
        
        # éšæœºæ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        split_point = int(len(X) * split_ratio)
        
        train_indices = indices[:split_point]
        val_indices = indices[split_point:]
        
        X_train, X_val = X[train_indices], X[val_indices]
        y_train, y_val = y[train_indices], y[val_indices]
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        
        return X_train_scaled, X_val_scaled, y_train, y_val, scaler
    
    def train_sklearn_model(self, model, X_train, y_train):
        """è®­ç»ƒsklearnæ¨¡å‹"""
        model.fit(X_train, y_train)
        return model
    
    def evaluate_sklearn_model(self, model, X_val, y_val, target_type):
        """è¯„ä¼°sklearnæ¨¡å‹"""
        y_pred = model.predict(X_val)
        
        if target_type == 'regression':
            score = mean_absolute_error(y_val, y_pred)
        else:
            score = accuracy_score(y_val, y_pred)
            
        return score, y_pred
    
    def train_pytorch_model(self, model, X_train, y_train, target_type, epochs=100):
        """è®­ç»ƒPyTorchæ¨¡å‹"""
        # è½¬æ¢ä¸ºå¼ é‡
        X_train_tensor = torch.FloatTensor(X_train)
        if target_type == 'regression':
            y_train_tensor = torch.FloatTensor(y_train)
        else:
            y_train_tensor = torch.LongTensor(y_train)
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        class SimpleDataset(Dataset):
            def __init__(self, features, targets):
                self.features = features
                self.targets = targets
            
            def __len__(self):
                return len(self.features)
            
            def __getitem__(self, idx):
                return self.features[idx], self.targets[idx]
        
        dataset = SimpleDataset(X_train_tensor, y_train_tensor)
        train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
        
        # è®­ç»ƒé…ç½®
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        
        if target_type == 'regression':
            criterion = nn.MSELoss()
        elif target_type == 'binary':
            criterion = nn.BCELoss()
        else:
            criterion = nn.CrossEntropyLoss()
        
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # è®­ç»ƒå¾ªç¯
        model.train()
        for epoch in range(epochs):
            epoch_loss = 0
            for batch_X, batch_y in train_loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                
                optimizer.zero_grad()
                outputs = model(batch_X)
                
                if target_type == 'multiclass':
                    loss = criterion(outputs, batch_y)
                else:
                    loss = criterion(outputs, batch_y)
                
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            if (epoch + 1) % 20 == 0:
                print(f"      è½®æ¬¡ {epoch+1}, æŸå¤±: {epoch_loss/len(train_loader):.4f}")
        
        return model
    
    def evaluate_pytorch_model(self, model, X_val, y_val, target_type):
        """è¯„ä¼°PyTorchæ¨¡å‹"""
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        X_val_tensor = torch.FloatTensor(X_val).to(device)
        
        model.eval()
        with torch.no_grad():
            outputs = model(X_val_tensor)
            
            if target_type == 'multiclass':
                _, predictions = torch.max(outputs, 1)
                predictions = predictions.cpu().numpy()
            elif target_type == 'binary':
                predictions = (outputs > 0.5).int().cpu().numpy()
            else:
                predictions = outputs.cpu().numpy()
        
        if target_type == 'regression':
            score = mean_absolute_error(y_val, predictions)
        else:
            score = accuracy_score(y_val, predictions)
            
        return score, predictions
    
    def run_single_experiment(self, features_df, feature_cols, target_type='regression', 
                            experiment_num=1, models_to_run=None):
        """è¿è¡Œå•æ¬¡å®éªŒï¼ˆä¸€æ¬¡åˆ’åˆ†ï¼‰"""
        print(f"\nğŸ”¬ å®éªŒ {experiment_num} - {target_type.upper()}ä»»åŠ¡")
        print("-" * 40)
        
        # å‡†å¤‡æ•°æ®
        X, y = self.prepare_data(features_df, feature_cols, target_type)
        
        # éšæœºåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train, X_val, y_train, y_val, scaler = self.create_train_val_split(
            X, y, split_ratio=0.8, random_state=42 + experiment_num
        )
        
        print(f"   æ•°æ®åˆ’åˆ†: è®­ç»ƒé›† {len(X_train)} æ ·æœ¬, éªŒè¯é›† {len(X_val)} æ ·æœ¬")
        
        # å®šä¹‰è¦è®­ç»ƒçš„æ¨¡å‹
        if models_to_run is None:
            models_to_run = ['RandomForest', 'GradientBoosting', 'DeepLearning']
        
        experiment_results = {}
        
        for model_name in models_to_run:
            print(f"   è®­ç»ƒ {model_name}...")
            
            if model_name == 'RandomForest':
                if target_type == 'regression':
                    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                else:
                    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
                
                trained_model = self.train_sklearn_model(model, X_train, y_train)
                score, _ = self.evaluate_sklearn_model(trained_model, X_val, y_val, target_type)
                
            elif model_name == 'GradientBoosting':
                if target_type == 'regression':
                    model = GradientBoostingRegressor(n_estimators=100, random_state=42)
                else:
                    model = GradientBoostingClassifier(n_estimators=100, random_state=42)
                
                trained_model = self.train_sklearn_model(model, X_train, y_train)
                score, _ = self.evaluate_sklearn_model(trained_model, X_val, y_val, target_type)
                
            elif model_name == 'SVM':
                if target_type == 'regression':
                    model = SVR(kernel='rbf', C=1.0)
                else:
                    model = SVC(kernel='rbf', C=1.0, random_state=42)
                
                trained_model = self.train_sklearn_model(model, X_train, y_train)
                score, _ = self.evaluate_sklearn_model(trained_model, X_val, y_val, target_type)
                
            elif model_name == 'DeepLearning':
                # å®šä¹‰æ·±åº¦å­¦ä¹ æ¨¡å‹
                class DeepNet(nn.Module):
                    def __init__(self, input_size, output_type='regression'):
                        super().__init__()
                        self.output_type = output_type
                        
                        self.network = nn.Sequential(
                            nn.Linear(input_size, 128),
                            nn.ReLU(),
                            nn.Dropout(0.3),
                            nn.Linear(128, 64),
                            nn.ReLU(),
                            nn.Dropout(0.2),
                            nn.Linear(64, 32),
                            nn.ReLU(),
                        )
                        
                        if output_type == 'regression':
                            self.output_layer = nn.Linear(32, 1)
                        elif output_type == 'binary':
                            self.output_layer = nn.Sequential(
                                nn.Linear(32, 1),
                                nn.Sigmoid()
                            )
                        else:
                            self.output_layer = nn.Linear(32, 3)
                    
                    def forward(self, x):
                        x = self.network(x)
                        return self.output_layer(x).squeeze()
                
                input_size = X_train.shape[1]
                model = DeepNet(input_size, target_type)
                trained_model = self.train_pytorch_model(model, X_train, y_train, target_type, epochs=50)
                score, _ = self.evaluate_pytorch_model(trained_model, X_val, y_val, target_type)
            
            # è®°å½•ç»“æœ
            experiment_results[model_name] = score
            
            metric_name = "MAE" if target_type == 'regression' else "å‡†ç¡®ç‡"
            print(f"     {model_name}: {metric_name} = {score:.4f}")
        
        return experiment_results
    
    def run_three_experiments(self, features_df, feature_cols, target_type='regression'):
        """è¿è¡Œä¸‰æ¬¡å®éªŒå¹¶è®¡ç®—å¹³å‡å‡†ç¡®ç‡"""
        print(f"\nğŸ¯ å¼€å§‹ä¸‰æ¬¡å®éªŒéªŒè¯ - {target_type.upper()}ä»»åŠ¡")
        print("=" * 60)
        
        all_results = {}
        
        for exp_num in range(1, 4):
            # è¿è¡Œå•æ¬¡å®éªŒ
            results = self.run_single_experiment(
                features_df, feature_cols, target_type, exp_num
            )
            all_results[f'experiment_{exp_num}'] = results
        
        # è®¡ç®—å¹³å‡å‡†ç¡®ç‡
        average_scores = self.calculate_average_scores(all_results)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        self.display_final_results(all_results, average_scores, target_type)
        
        return all_results, average_scores
    
    def calculate_average_scores(self, all_results):
        """è®¡ç®—å¹³å‡åˆ†æ•°"""
        models = list(all_results['experiment_1'].keys())
        average_scores = {}
        
        for model in models:
            scores = []
            for exp_name in all_results.keys():
                scores.append(all_results[exp_name][model])
            average_scores[model] = {
                'mean': np.mean(scores),
                'std': np.std(scores),
                'scores': scores
            }
        
        return average_scores
    
    def display_final_results(self, all_results, average_scores, target_type):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        print(f"\nğŸ“Š {target_type.upper()}ä»»åŠ¡ - ä¸‰æ¬¡å®éªŒæœ€ç»ˆç»“æœ")
        print("=" * 50)
        
        metric_name = "MAE" if target_type == 'regression' else "å‡†ç¡®ç‡"
        
        # æ˜¾ç¤ºæ¯æ¬¡å®éªŒçš„ç»“æœ
        print("å„æ¬¡å®éªŒç»“æœ:")
        for exp_name, results in all_results.items():
            print(f"  {exp_name}: ", end="")
            for model, score in results.items():
                print(f"{model}: {score:.4f}  ", end="")
            print()
        
        print(f"\nå¹³å‡{metric_name}:")
        for model, stats in average_scores.items():
            print(f"  {model}: {stats['mean']:.4f} Â± {stats['std']:.4f}")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        if target_type == 'regression':
            best_model = min(average_scores.items(), key=lambda x: x[1]['mean'])[0]
            best_score = average_scores[best_model]['mean']
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å¹³å‡MAE: {best_score:.4f})")
        else:
            best_model = max(average_scores.items(), key=lambda x: x[1]['mean'])[0]
            best_score = average_scores[best_model]['mean']
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å¹³å‡å‡†ç¡®ç‡: {best_score:.4f})")

def run_complete_validation(features_df, feature_cols):
    """è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹"""
    print("ğŸš€ å¼€å§‹å®Œæ•´çš„æ¨¡å‹è®­ç»ƒä¸éªŒè¯æµç¨‹")
    print("=" * 60)
    
    validator = ThreeFoldValidator()
    
    # å›å½’ä»»åŠ¡ä¸‰æ¬¡å®éªŒ
    print("\n" + "="*60)
    reg_results, reg_averages = validator.run_three_experiments(
        features_df, feature_cols, 'regression'
    )
    
    # åˆ†ç±»ä»»åŠ¡ä¸‰æ¬¡å®éªŒ
    print("\n" + "="*60)
    cls_results, cls_averages = validator.run_three_experiments(
        features_df, feature_cols, 'multiclass'
    )
    
    return {
        'regression': {'results': reg_results, 'averages': reg_averages},
        'classification': {'results': cls_results, 'averages': cls_averages}
    }